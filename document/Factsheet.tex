%% Factsheet template for NTIRE 2017 challenge on image super-resolution
%% 
%%

\documentclass{article}

\title{Title of the contribution\\--NTIRE2017 factsheet--}

\begin{document}

\maketitle

This factsheet template is meant to structure the description of the contributions made by each participating team in the NTIRE 2017 challenge on image super-resolution.

Ideally all the aspects enumerated below should be addressed.
The provided information, the codes/executables and the achieved performance on the testing data are used to decide the awardees of the NTIRE2017 challenge.

The reproducibility is a must and needs to be checked for the final test results in order to qualify for the NTIRE awards. Note that most awards will go to the teams with both released of codes and executables. 

We will favor the teams with solutions validated on more than one of the 6 competitions of the NTIRE2017. Ideally for all 3 track 1 competitions and/or all 3 track 2 competitions. 

The main winners will be decided based on overall quantitative performance and a number of awards will go for novel, interesting solutions and for solutions that stand up as the best in a particular subcategory the judging committee will decided. Please check the competitions webpages and forums for more details.

The winners, the awardees and the top ranking teams will be invited to co-author the NTIRE 2017 challenge report and to submit papers with their solutions to the NTIRE 2017 workshop.

\section{Team details}

\begin{itemize}
\item Team name                                  
\item Team leader name                           
\item Team leader address, phone number, and email 
\item Rest of the team members        
\item Team website URL (if any)                   
\item Affiliation
\item Affiliation of the team and/or team members with NTIRE2017 sponsors (NVIDIA, SenseTime, Twitter, Google)
\item User names and entries on the NTIRE2017 Codalab competitions (development/validation and testing phases)
\item Best scoring entries of the team during development/validation phase
\item Link to the codes/executables of the solution(s)
\end{itemize}

\section{Contribution details}

\begin{itemize}
\item Title of the contribution                                  
\item General method description                                
\item Description of the particularities of the solutions deployed for each of the challenge competitions or tracks
\item References                                               
\item Representative image / diagram of the method(s)             
\end{itemize}

\section{Global Method Description}

\begin{itemize}
\item Total method complexity: all stages
\item Which pre-trained or external methods / models have been used (for any stage, if any) 
\item Which additional data has been used in addition to the provided NTIRE training and validation DIV2K data (at any stage, if any) 
\item Training description
\item Testing description
\item Quantitative and qualitative advantages of the proposed solution
\item Results of the comparison to other approaches (if any)
\item Results on other standard benchmarks such as Set5, Set14, B100, Urban100 (if any)
\item Novelty degree of the solution and if it has been previously published
\end{itemize}

\section{Track 1: Bicubic downsampling}
Any particularities of the deployed solution for the Track 1 competitions ($\times2$, $\times3$, $\times 4$) (if applicable)
\section{Track 2: Unknown downsampling}
Any particularities of the deployed solution for the Track 2 competitions ($\times2$, $\times3$, $\times 4$) (if applicable)

\section{Ensembles and fusion strategies}
\begin{itemize}
\item Describe in detail the use of ensembles and/or fusion strategies (if any).
\item What was the benefit over the single method? 
\item What were the baseline and the fused methods?
\end{itemize}

\section{Technical details}
\begin{itemize}
\item Language and implementation details (including platform, memory, parallelization requirements)
\item Human effort required for implementation, training and validation?
\item Training/testing time? Runtime at test per image.
\item Comment the robustness and generality of the proposed solution(s)? Is it easy to deploy it for other sets of downscaling operators? 
\item Comment the efficiency of the proposed solution(s)?
\end{itemize}

\section{Other details}
\begin{itemize}
\item Planned submission of a solution(s) description paper at NTIRE2017 workshop.
\item General comments and impressions of the NTIRE2017 challenge. 
\item What do you expect from a new challenge in image restoration and enhancement?
\item Other comments: encountered difficulties, fairness of the challenge, proposed subcategories, proposed evaluation method(s), etc.
\end{itemize}

\end{document}